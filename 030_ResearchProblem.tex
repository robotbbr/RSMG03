\chapter{Research Problem}

The last chapter presented the state of the art in activity recognition.
While the subject has been studied extensively in the recent years, the problem still provide a fertile research field to test different approaches.
Activity recognition is particularly relevant for autonomous robots, which provide important benefits but also trigger new challenges.
On the other hand, despite the main principles of ASP were stated in the late 1980s, the possibilities of this approach haven't been completely exploited and it still remains as a very active research area in the field of Logic Programming.
We're interested in exploring the possibilities of ASP in the context of autonomous robotics.
In general, as a tool to handle problems in the knowledge representation and reasoning areas, and in particular, within the problem of activity recognition

This chapter presents the main problem to be studied in this project: activity recognition with a mobile robot.
It also introduces the structure of a framework to build up a solution to the problem that puts emphasis the usage of ASP, and that can be integrated with current state of the art hardware and software tools. 
This is presented in the context of the \textit{Library scenario} (section \ref{sec_Library}) to ground the concepts to an example, and to set the path for future work.
Finally, the approach is discussed to expose its strengths and weaknesses, and to present expected outcomes.

\section{Problem Description} \label{sec_problem}

% Description of the problem
The subject of study in this project is ASP-based activity recognition with a mobile robot.

As mentioned at the beginning of this chapter, the problem of activity recognition is relevant in the context of robotics.
At the same time, ASP offers an interesting and novel approach to the problem.
These three parts, Activity Recognition, Robotics and ASP, have been studied separately in extension, however, their joint possibilities are still uncovered.
The focus of this project is to study the problem of activity recognition with an autonomous robot, and particularly how to exploit an ASP-based approach.

Human activities can be classified in different ways and with different grade of detail.
In \citep{Turaga2008_MaRecHuAcSurv}, two non-exclusive categories are used: actions, performed by a person, and activities, performed by many persons.
One more descriptive categorization has been given in \citep{Aggarwal11_HumanActivity}, separating activities in four classes:

\begin{description}
\item[Gestures] Elementary movements of a person's body part, and are the atomic components describing a meaningful motion of a person. 
E.g. `stretching an arm', `raising a leg'.
\item[Actions] Single person activities that may be composed of multiple gestures organized temporally. 
E.g. `walking', `waving'.
\item[Interactions] Human activities that involve two or more persons and/or objects. 
E.g. `Two persons fighting', `a person eating an apple'.
\item[Group activities] The activities performed by conceptual groups of multiple persons and/or objects. 
E.g. `a football team playing a match', `a group of students making an exam'.
\end{description}

All of these categories require to be able to sense humans with different level of detail.
For example, gestures require specific algorithms (e.g. hand detection, face detection, skeleton tracing, etc.) while long distant pedestrian tracking algorithms may consider persons as \textit{moving dots}.
With this in mind, target activities should be defined within the sensory constraints of a mobile robot.

The goal application is to be able to build a system on top of a robot that can be able to observe and follow the ongoing activities in a location (e.g. a library), from different points of view, but from a single one. 
This is the way in which humans perceive, however, this also drives to a situation of incomplete information as the robot won't have enough sensory information from all the environment. 
It is a thesis in this project that the lack of sensory information can be complemented with a stronger cognitive approach, in this case knowledge representation and reasoning capabilities.

This activity information can be used in different ways, but particularly as semantic knowledge, which has a meaning and a context and that can be used for reasoning.
This is useful for a robot to have a qualitative description of the environment, to augment its navigation capabilities and task planning, and also to bridge the gap in human-robot interaction \citep{Kostavelis2015_SemMapSurv}.

Going back to the library setting described in section \ref{sec_Library}. %TODO %TODO Add example


\section{Methodology}

This section presents the proposed approach to tackle the problem.

First, the target platform is an autonomous mobile robot.
In a general fashion, a control system for a robot can be simplified as a perception-action loop. %TODO %TODO Add image Perception-Action
An activity recognition system fits in by providing interesting features from the environment (activities) that a robot can use to improve its performance.

The system requires some input, particularly observations from the environment, which are compulsory.
Additionally to this, symbolic information is also going to be required in the form of a semantic map and domain knowledge.
Finally, the representations of activities are also considered as an input.
The output of the system is a set of activities and features found on the environment, within a degree of confidence.

%TODO %TODO Overall image

Now let's look the inside of the proposed system.

\subsection{Sensing}

The end target for this project are autonomous mobile robots, with this in mind, all the sensing in charge of the robot. 
No building sensing (e.g. CCTV) or portable devices (e.g. cellphone, laptop) are allowed, this is the goal.
We are looking forward to use state-of-the-art sensing techniques, however, as completely reliable sensing is not assured and improving sensing algorithms is beyond the scope of this project, the use of simulations and environment marks is considered for experimental purposes. %TODO Add "see next section/chapter" 

The features to be sensed will depend on the type of activities to be recognized.
By using the categorization of activities mentioned in section \ref{sec_problem}, we are interested in the mid-level activities.
This considers single human activities and interactions with other humans and/or objects, and excludes gestures and group activities.
So, human and object sensing are needed.
In the same fashion, the aim is to provide a robot with some understanding of activities within a spatio-temporal conceptualization by building a semantic map, so location and mapping are also a requirement, i.e. environment sensing.

All these give us a path to decompose the scene in three different categories within a 3D space: humans (detection, recognition, kinematic description, etc.), objects (detection, recognition, kinematic description, etc.) and environment (location).
%TODO  Add Image reference and image of scene decomposition.

\subsection{Qualitative Spatio-Temporal Representations}
QSTR were introduced briefly mentioned in chapter \ref{ch_relatedwork}.
They provide formal models to represent and reason about geometrical entities in space and time.
Space is handled with Qualitative Spatial Relations. %TODO Expand explanation and reference.
Time is usually modelled in events using Allen's interval algebra \ref{Allen83_MaintainingKnowledgeTemporal}. %TODO expand

A qualitative approach is desired as it proofs to be more robust to dynamic and non-deterministic environments.
It also avoids to depend on training data or parameters which are specific to a particular location, and drives the data towards a symbolic representation.
Finally, because it is a more human-alike approach, desired for a better human-robot interaction.

The idea here is to convert quantitative observations to qualitative, by representing the spatio-temporal relations between objects and/or persons, and eventually, with the environment too (e.g. regions of interests).

While it could be a temptation to build all possible relations between the entities of interest in a scene, this has proved to be an non-efficient approach \citep{Sridhar10_UnsupervisedLearning}, mostly because the combinatorial explosion of the amount  of possible relations. The relations to be handled have to be chosen in a more \textit{intelligent} fashion.

%TODO Add example.

\subsection{Knowledge Base}
Additionally to the observations, a knowledge is required, which contains symbolic information that will be used to process the 
observations.
First, and most importantly, the description of activities are required.
This also will include a description from the environment (i.e. a semantic map) and other domain knowledge that can potentially be used to infer new knowledge.

An important question here is about the origin of this knowledge, and in particular of the activities.
The simplest approach is to define the activity representations manually.
For some specific activities this can be enough, however, in general other strategies are required.
Activities can be learnt, from a human demonstrator or by analysing data from repeated situations.
Finally the representation of activities can be consulted in larger knowledge databases using some existing tools, e.g. wikiHow \citep{web_WikiHow}, OpenCyc \citep{web_OpenCyc}, KnowRob \citep{Tenorth09_Knowrob}, RoboEarth \citep{Zweigle2009_RoboEarth}.
Here the focus is to share common knowledge for robots instead of learning it every time, as this takes considerable computational effort.


%\subsection{Maintaining observations}

%The qualitative observations need to be maintained, because new observations will arrive along time, and some of them will need to be updated.
%For example, the qualitative representation of a person approaching to the entrance door may take many samples until the person is seen %crossing the door frame, and all these \textit{person-approaching-door} observations need to be merged into a single event and only the temporal relations between events may require to be updated.
%TODO Add example "Walking person to".


\subsection{Inferring activities}

At this point, the system has a set of qualitative observations in time and space of interesting features.
Along time, these observations should be updated or thrown to have a compact set of valid premises.

Now, the problem is to map the observations into an activity representation. 
As mentioned before, ASP provides a the techniques to solve difficult combinatorial problems. and in particular, search problem as satisfiability problems (SAT).
This is how, the observations become a set of constraints to find definitions (of activities) that satisfy them.

It should be noticed that the observations do not necessarily fulfil all the required parameters in the definition.
However, here is where ASP shows its usability by being able to provide candidate solutions, even when there are unknown parameters.

At the end we have a solution, or many possible solutions to the problem of correspondence between the observations and the defined activities.

%TODO Expand and include the example.


\subsection{Discriminate activities}

If there is unique correspondence, then this can be taken as solution for the problem\footnote{Nevertheless, it should the noted that, even though the ASP premises have a logical meaning, it will be very difficult to guarantee complete certainty.}. 
However, it is expected that this will barely be the case.
But, there are many possibilities available to find a solution.

First, additional knowledge sources can be considered.
These are, a semantic map of the environment and domain knowledge, which can be represented in ASP.

Secondly, a learning strategy can be implemented to find patterns of \textit{frequently occurring activities} in particular locations, by specific persons or with related objects. 
This is, to maintain a knowledge base of experiences.

Finally, the described system can take advantage of the fact that the robot is active.
The robot can interact with the environment and with persons, and it can choose points of interest in the scene.

For example, a robot may be watching a person in the library with an unknown object in the hands. 
The robot can create a belief, by context and by experience, that the object is a book.
However, he can also go closer to that person to have a better look of the object.
Finally, interaction is also possible, and the robot can simply ask the person which object is he/she holding.

One important observation should be made in the previous example, and this is, the fact that the robot should figure where to look, or what information is missing to improve its conclusions. 
This is an advantage, but also a necessity as it is very unlikely that a robot can have complete coverage of a scene.
In the example, the required knowledge is the identification of the object, which can be helpful to discriminate between to activities, e.g. eating and studying. 
Knowing which parts of the missing knowledge will help to improve the conclusions, or which ones are more important, gives a path to plan an active strategy for the robot to fulfil those perception holes.

% Alternatives for each part
% > Observations
% > Knowledge (where? & how?, I'll do it by hand, but it's important to mention alternatives).
% > Representations
% *** CHECK THE orgnanization from the surveys
%   - Modelling activities in space (QSR)
%   - Modelling activities in time  (QSTR ~ Allen's, Fluent, Event, etc).
%   - Modelling activities semantically (Ontologies + Hierarchies)
% > Inference

% Test example

\section{Evaluation} % Or alternatives

Once presented the problem and the proposed solution, some remarks can be made to evaluate its advantages and its limitations, and how these can eventually be tackled.

First, this project makes emphasis in the use of a robot, which has some evident limitations.
Sensors are constrained to defined ranges and the thrown data usually presents noise.
Actuators also present inaccuracies and time-delayed responses.
Processing capabilities are also limited in a robot, so the amount of data collected with a robot should be minimized and processed efficiently whenever is possible.
%This is, however, the current state in robotics and this is considered by considering sensor models, 

Regarding ASP, here is used for knowledge representation and reasoning purposes. 
It can also provide a path to plan actions for the robot.
ASP should be used with reserve as it is used to model combinatorial NP-hard problems.
With this in mind, should be noted that ASP implementations are limited in efficiency and the modelled problems can grow very easily.
This is considered in this project by restricting the domain application (to a library), the amount and granularity of the descriptions for activities, objects and places.




% Main parts of the problem

% A - Scene decomposition (locations, objects, persons)
%   > from observations to scene reconstruction

% B - 

% B - Representation 
% Modelling in space (QSR)
% Modelling in time (QSTR)
