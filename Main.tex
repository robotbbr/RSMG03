\documentclass[a4paper, 12pt, openany, oneside]{book}
\input{inc/Header.tex} % Included packages located in a separate file
\pagestyle{plain} %Page numbers on the bottom

\begin{document}

% Front page
\pagestyle{emty} %No numbers
\input{000_TitlePage.tex}
\cleardoublepage

% Table of Contents
\newpage
\pagenumbering{roman}
\tableofcontents

% Main Chapters
\newpage
\pagestyle{plain}
\pagenumbering{arabic}
% Abstract
\input{010_Introduction.tex} % Intro & Motivation (Open areas proposed in the literatures)
% Outcome
%\input{020_RelatedWork.tex} % "Related Work" Literature rev (separated areas, in my case AR + ASP + KRR(incomplete) + Semantic Map)

%================================================
%================================================
%================================================
\chapter{Related Work}

% 0 - GENERALITIES
% Perception
% Symbol ground
% Anchoring
% Frame Problem

\section{General antecedents - Perception in AI}

Perception, as a cognitive process, has been studied widely in Psychology.  
Some of these studies refer on how information is processed and which parts of it are essential to make sense properly of a sensory input.
In \citep{Heider1944_Experimental}, an animated film was created using only moving polygons to demonstrate how the motion of abstract entities can be interpreted by a human observer.
In \citep{Johansson1973_VisualPer}, locomotion patterns of living organisms using visual marks are studied. 
By this mean, the emphasis was put in the motion pattern created by the marks rather than in the moving body, whose dimensions and shape were unknown.


In Artificial Intelligence, perception has been treated mostly by the computer vision research community.
Earlier works can be traced back to the 1960s, as part of the effort to mimic human-like intelligence using visual perception components. The main difference between computer vision and image processing has been the desire to recover the three-dimensional structure of the world from images, and to use this as a stepping stone towards full scene understanding \citep{Winston1975_PsyCV}. 

One of the earlier works in 3D reconstruction from a single image is found in \citep{Roberts1963_PhDThesis}.
The developed system as able to reconstruct geometrical bodies with flat surfaces by recognizing the borders of the bodies in the scene and later analysing the shades of their visible surfaces.
%TODO Need to add Adolfo Guzman Arenas work here. +-
In the late 1960s, the \textit{block's world} was used as a test scenario for intelligent systems, particularly regarding knowledge representation, reasoning and planning.
In the block's world, the actual state $A$ and a desired future state $B$ of the environment are given.
The goal is to autonomously generate a plan to transform $A$ into $B$ by the manipulation of the blocks in scene.
One important characteristic of the problem is the requirement of a symbolic representation.
The problem was used as a test case for the robot Shakey \citep{Nilsson84_Shakey}.
In \citep{Barrow1971_RelatDesc} object recognition was studied by decomposing an image into regions and describing the spatial relations between them, in a more qualitative, rather than the traditional quantitative, approach.

%Finally, during the 1980s an approach to perception with emphasis in action feedback became popular
%TODO Complete Active Perception.

%TODO Need to mention QSR.
%TODO Need to mention KRR (ASP, DL, Ontologies, Naive Ph, etc.).


\section{Activity Recognition} % Emphasis in the taxomony of the area

Activity recognition is an important research area in the context of automated perception. 
It has many applications as surveillance, inspection, verification, generation of automated reports, etc.
The main goal is to automatically analyse the ongoing activities from a sensory source (a video sequence in most of the cases).

Activities play a relevant role in the interpretation of a scene, not only in physical terms (space and time), but also symbolically as they can usually be associated with a meaning and a domain. 

Human activities are difficult to classify because they cover a broad range of situations in different contexts, and they depend on many parameters.
Regarding their complexity, activities can be treated as hierarchical entities because high-level activities are usually composed of simpler actions.
In \citep{Turaga2008_MaRecHuAcSurv}, two non-exclusive categories are used: actions and activities.
The first one is used for simple actions performed preferably by a individual, and activities are treated as a complex sequence of actions performed by several individuals. In \citep{Aggarwal11_HumanActivity}, a four layers categorization is proposed:

\begin{description}
\item[Gestures] Elementary movements of a person's body part, and are the atomic components describing a meaningful motion of a person. 
E.g. `stretching an arm', `raising a leg'.
\item[Actions] Single person activities that may be composed of multiple gestures organized temporally. 
E.g. `walking', `waving'.
\item[Interacions] Human activities that involve two or more persons and/or objects. 
E.g. `Two persons fighting', `a person eating an apple'.
\item[Group activities] The activities performed by conceptual groups of multiple persons and/or objects. 
E.g. `a football team playing a match', `a group of students making an exam'.
\end{description}

The research in activity recognition goes in different directions depending on many factors as specific domains (e.g. robotics, gaming), features of interest in the scene (e.g. abnormality detection, verification), sensory capabilities of the system (e.g. computer vision, pervasive). It usually reflects interest in specific parts of the problem as sensing, scene reconstruction, representation of activities, pattern recognition, reasoning, etc.

In \citep{Aggarwal11_HumanActivity} a taxonomy is proposed to organize the research in the area, Fig. \ref{fig:taxonomy}.  

\begin{figure}[h]
\centering
\includegraphics[width=\textwidth]{fig/img_Aggarwal_Taxonomy.pdf}
\caption{The taxonomy of research in activity recognition described in \cite{Aggarwal11_HumanActivity}.}
\label{fig:taxonomy}
\end{figure}

\subsection{Single-layered approaches}
The representation and recognition of activities is performed using raw sensory data\footnote{The original survey \citep{Aggarwal11_HumanActivity} describes single layered approaches as image-based approaches, but it leaves out the systems with other sensing capabilities (e.g. 3D sensors, sonars). 
However, they can be included too if it is clear that the representation and recognition of activities is based in the processing of raw sensory data.}. 
Sensory data is processed to obtain particular descriptive features of the scene which are compared with known activity patterns. 
These patterns can be obtained in a supervised or unsupervised fashion (e.g. common occurrences of a specific action). 
Most of them are based in computer vision and machine learning techniques.

Single-layered approaches are suitable for recognition of short-term and simple activities as gestures, movements of the body or simple interaction with an object. 
This is because the amount of collected data, which is going to be processed, grows very easily and long-term activities would require the processing of larger amounts of data. 
Also, because activities are not always performed in the same way, even by the same person; the shorter the activity, the more accuracy that will be attained.  
An finally, because they are dependant on the conditions of the sensors and from the environment (e.g. different light conditions, a particular point of view) and noise should be considered.


\subsubsection{Continuous approaches\footnote{`Space-time approaches' in \citep{Aggarwal11_HumanActivity}}} % BEFORE: Space-Time approaches

The activities are recognized by analysing continuously sensory data projected in time. 
A volume (or hyper-volume) is built from the sensory data and particular features are extracted and compared with known patterns.
The dimension of the data will depend on the sensing capabilities of the system; for example, video analysis would require 3 dimensions $(X,Y,T)$ and a RGBD camera would be able to use 4 dimensions $(X,Y,Z,T)$, etc. %TODO Consider RGB values..., what happens with other dimensions, e.g. temperature?
Continuous approaches can also be classified depending on the features that are used to describe activities (volumes, trajectories, point descriptors, etc.).

In \citep{Bobick2001_RecHuMovTemp} a video signal of aerobics exercises is analysed by attaching to every pixel a vector indicating the precence of motion and the recency of motion in a sequence. 
The vector sequences are compared in time with known pattern of exercises. 
The system was able to recognize the activities in real time, and with a linear temporal temporal variance. 

In \citep{Ke2007_SpTmpShapeAR} activity recognition is performed by extracting from a video signal sequences that are similar to the known activity pattern, using a shape-based representation. 
Then a volume is built by concatenating the video frames in time. Similar neighbour regions are then clustered to create a volume. 
Finally the shapes of the volumes are compared to known patterns of activities.


\subsubsection{Sequential approaches} %TODO Go deeper.
Sequential approaches look to recognize activities by analysing a sequence of extracted features. First the sensory data is processed to extract particular features, which will be concatenated in time. Then sequential methods are applied to to search for sequences that coul eventually match with the pattern of a known activities. In case of that the sequence is corrupted, a probabilistic approach can be applied to decide the occurrence of the activity.

Sequential approaches can be classified depending on the used recognition methodology in exemplar-based and model-based. 

In exemplar-based sequential approaches a sequence in time is created by extracting particular features from the incoming sensory data. In \citep{Veeraraghavan2006_FuncSpcAct} high-level actions are treated as a sequence in time of atomic actions. The same activity performed in two different occasions can create two different sequences because of an execution in a different speed. The authors develop a method to learn the the pattern time variances in the activity sequence to be able to recognize activities performed at different speeds, or with eventual pauses.

The second one, creates a sequence in time of states, which might be separated in time, and  creates a statistical model to test the belonging of that pattern to a known class of activity. Hidden Markov models (HMMs) and Dynamic Bayesian networks (DBNs) are widely used in this approach. The activity is modelled in terms of hidden states and then transition probabilities are trained. The model will reflect the similarity of a sequence of states with a probability value. These methods can be robust in realistic cases where the sequence of states is corrupted or incomplete.

The first work to use probabilistic graphical models to recognize activities is \citep{Yamato1992_RecHA_HMM}. They transformed a sequence of images into an image feature vector sequence, and then into a symbol sequence by vector quantization. They used a set of HMMs to model the activities to be recognized and dataset to optimize the parameters of the model. Their results reflect a good and reliable performance of HMMs to model human activities. 






\subsection{Hierarchical approaches}
They describe high-level activities in terms of simpler ones, building multiple layers that are suitable to represent complex activities.

Hierarchical approaches can be classified regarding the used recognition methodology as statistical, syntactical and description-based.

\subsection{Statistical}
They are based in the construction of statistical state-based models concatenated hierarchically (e.g. layered hidden Markov models) to represent and recognize high-level human activities.

\subsubsection{Syntactic}
A grammar syntax is used to model sequential activities (e.g. stochastic context-free grammar). 
By this mean, a high level activity is represented as a string of atomic level activities that takes part.

\subsubsection{Description-based}
Activities are represented by the description of sub-events and their spatial, temporal and logical structures.



% 2 - ACTIVITY RECOGNITION PROBLEM
% Approaches (camera, wearable device, ubiquitous computing)
% Main branches (single layer, multpiple layer)
% Hierarchical approaches

%\section{Activity Recognition (robots, ASP, QSR, 3D)}
% 1.5 ACTIVITY RECOGNITION WITH A MOBILE ROBOT
%A robot can be roughly conceived as a physical entity capable of sensing and performing actions in the world.
%With this in mind, it seems clear that a robot, with sufficient sensing capabilities, is a good candidate to perform the task.

%\subsection{ASP}

% 2 - ANSWER SET PROGRAMMING
% General background
% Related work to AR


% 3 - ASP + Robots -> ROSoClingo
% 
%================================================
%================================================
%================================================


%\input{030_ResearchProblem.tex} % (Mike --> Model & Methodology) % Research Problem (Analysis) (Problem Definition -> Rafee)
%\input{040_Methodology.tex}% * Methodology (Here goes the strategy to face the problem, THE PROPOSAL!!)
%\input{050_Evaluation.tex}% Evaluation (Pros + Cons, Possible failures, etc.)
%\input{060_WorkPlan.tex}% * Work Plan (Research Goals+- --> Paul Engelfield)
% Work Done (so far)
% Timetable

% MAke a Timeline of AR
% Check "Paul Engelfield" --> Good Report

% *5min sketch of the report at the begining

% Bibliography
\clearpage
\bibliographystyle{abbrvnat}
\bibliography{/home/kilgore/Dropbox/Public/Docs/mabp_bibliography.bib}
%\bibliography{Bibliography.bib}


\end{document}
