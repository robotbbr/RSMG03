\documentclass[a4paper, 12pt, openany, oneside]{book}
\input{inc/Header.tex} % Included packages located in a separate file
\pagestyle{plain} %Page numbers on the bottom

\begin{document}

% Front page
\pagestyle{emty} %No numbers
\input{000_TitlePage.tex}
\cleardoublepage

% Table of Contents
\newpage
\pagenumbering{roman}
\tableofcontents

% Main Chapters
\newpage
\pagestyle{plain}
\pagenumbering{arabic}
% Abstract
%\input{010_Introduction.tex} % Intro & Motivation (Open areas proposed in the literatures)
% Outcome
%\input{020_RelatedWork.tex} % "Related Work" Literature rev (separated areas, in my case AR + ASP + KRR(incomplete) + Semantic Map)

%================================================
%================================================
%================================================
\chapter{Related Work}

% 0 - GENERALITIES
% Perception
% Symbol ground
% Anchoring
% Frame Problem

\section{General antecedents - Perception in AI}

Perception, as a cognitive process, has been studied widely in Psychology.  
Some of these studies refer on how information is processed and which parts of it are essential to make sense properly of a sensory input.
In \citep{Heider1944_Experimental}, an animated film was created using only moving polygons to demonstrate how the motion of abstract entities can be interpreted by a human observer.
In \citep{Johansson1973_VisualPer}, locomotion patterns of living organisms using visual marks are studied. 
By this mean, the emphasis was put in the motion pattern created by the marks rather than in the moving body, whose dimensions and shape were unknown.


In Artificial Intelligence, perception has been treated mostly by the computer vision research community.
Earlier works can be traced back to the 1960s, as part of the effort to mimic human-like intelligence using visual perception components. The main difference between computer vision and image processing has been the desire to recover the three-dimensional structure of the world from images, and to use this as a stepping stone towards full scene understanding \citep{Winston1975_PsyCV}. 

One of the earlier works in 3D reconstruction from a single image is found in \citep{Roberts1963_PhDThesis}.
The developed system as able to reconstruct geometrical bodies with flat surfaces by recognizing the borders of the bodies in the scene and later analysing the shades of their visible surfaces.
% TODO: Need to add Adolfo Guzman Arenas work here. +-
In the late 1960s, the \textit{block's world} was used as a test scenario for intelligent systems, particularly regarding knowledge representation, reasoning and planning.
In the block's world, the actual state $A$ and a desired future state $B$ of the environment are given.
The goal is to autonomously generate a plan to transform $A$ into $B$ by the manipulation of the blocks in scene.
One important characteristic of the problem is the requirement of a symbolic representation.
The problem was used as a test case for the robot Shakey \citep{Nilsson84_Shakey}.
In \citep{Barrow1971_RelatDesc} object recognition was studied by decomposing an image into regions and describing the spatial relations between them, in a more qualitative, rather than the traditional quantitative, approach.

%Finally, during the 1980s an approach to perception with emphasis in action feedback became popular
%TODO: Complete Active Perception.

%TODO: Need to mention QSR.
%TODO: Need to mention KRR (ASP, DL, Ontologies, Naive Ph, etc.).


\section{Activity Recognition} % Emphasis in the taxomony of the area

Activity recognition is an important research area in the context of automated perception. 
It has many applications as surveillance, inspection, verification, generation of automated reports, etc.
The main goal is to automatically analyse the ongoing activities from a sensory source (a video sequence in most of the cases).

Activities play a relevant role in the interpretation of a scene, not only in physical terms (space and time), but also symbolically as they can usually be associated with a meaning and a domain. 

Human activities are difficult to classify because they cover a broad range of situations in different contexts, and they depend on many parameters.
Regarding their complexity, activities can be treated as hierarchical entities because high-level activities are usually composed of simpler actions.
In \citep{Turaga2008_MaRecHuAcSurv}, two non-exclusive categories are used: actions and activities.
The first one is used for simple actions performed preferably by a individual, and activities are treated as a complex sequence of actions performed by several individuals. In \citep{Aggarwal11_HumanActivity}, a four layers categorization is proposed:

\begin{description}
\item[Gestures] Elementary movements of a person's body part, and are the atomic components describing a meaningful motion of a person. 
E.g. `stretching an arm', `raising a leg'.
\item[Actions] Single person activities that may be composed of multiple gestures organized temporally. 
E.g. `walking', `waving'.
\item[Interacions] Human activities that involve two or more persons and/or objects. 
E.g. `Two persons fighting', `a person eating an apple'.
\item[Group activities] The activities performed by conceptual groups of multiple persons and/or objects. 
E.g. `a football team playing a match', `a group of students making an exam'.
\end{description}

The research in activity recognition goes in different directions depending on many factors as specific domains (e.g. robotics, gaming), features of interest in the scene (e.g. abnormality detection, verification), sensory capabilities of the system (e.g. computer vision, pervasive). It usually reflects interest in specific parts of the problem as sensing, scene reconstruction, representation of activities, pattern recognition, reasoning, etc.

In \citep{Aggarwal11_HumanActivity} a taxonomy is proposed to organize the research in the area, Fig. \ref{fig:taxonomy}.  

\begin{figure}[h]
\centering
\includegraphics[width=\textwidth]{fig/img_Aggarwal_Taxonomy.pdf}
\caption{The taxonomy of research in activity recognition described in \cite{Aggarwal11_HumanActivity}.}
\label{fig:taxonomy}
\end{figure}

\subsection{Single-layered approaches}
These approaches are based in the representation and recognition of activities using raw sensory data\footnote{The original survey \citep{Aggarwal11_HumanActivity} describes single layered approaches as image-based approaches, but it leaves out the systems with other sensing capabilities (e.g. 3D sensors, sonars). However, they can be included too if it is clear that the representation and recognition of activities is based in the processing of raw sensory data.}.
%They are suitable for recognition of gestures and actions with sequential characteristics.

\subsubsection{Continuous approaches\footnote{Space-time aproaches in \citep{Aggarwal11_HumanActivity}}} % BEFORE: Space-Time approaches
The activities are represented continuously  by the sensory data projected in time. The dimension of the data will depend on the sensing capabilities of the system (e.g. XYT for video).

Continuous approaches can also be classified depending on the features that are used to describe activities: volumes, trajectories and local point descriptors.


\subsubsection{Sequential approaches} % TODO: Go deeper.
In these approaches the goal is to interpret a sequence of observations.

Sequential approaches can be classified depending on the used recognition methodology as exemplar-based and model-based.


\subsection{Hierarchical approaches}
They describe high-level activities in terms of simpler ones, building multiple layers that are suitable to represent complex activities.

Hierarchical approaches can be classified regarding the used recognition methodology as statistical, syntactical and description-based.

\subsection{Statistical}
They are based in the construction of statistical state-based models concatenated hierarchically (e.g. layered hidden Markov models) to represent and recognize high-level human activities.

\subsubsection{Syntactic}
A grammar syntax is used to model sequential activities (e.g. stochastic context-free grammar). By this mean, a high level activity is represented as a string of atomic level activities that takes part.

\subsubsection{Description-based}
Activities are represented by the description of sub-events and their spatial, temporal and logical structures.



% 2 - ACTIVITY RECOGNITION PROBLEM
% Historic origins
% Approaches (camera, wearable device, ubiquitous computing)
% Main branches (single layer, multpiple layer)
% Hierarchical approaches

%\section{Activity Recognition (robots, ASP, QSR)}
% 1.5 ACTIVITY RECOGNITION WITH A MOBILE ROBOT
%A robot can be roughly conceived as a physical entity capable of sensing and performing actions in the world.
%With this in mind, it seems clear that a robot, with sufficient sensing capabilities, is a good candidate to perform the task.

%\subsection{ASP}

% 2 - ANSWER SET PROGRAMMING
% General background
% Related work to AR


% 3 - ASP + Robots -> ROSoClingo
% 
%================================================
%================================================
%================================================


%\input{030_ResearchProblem.tex} % (Mike --> Model & Methodology) % Research Problem (Analysis) (Problem Definition -> Rafee)
%\input{040_Methodology.tex}% * Methodology (Here goes the strategy to face the problem, THE PROPOSAL!!)
%\input{050_Evaluation.tex}% Evaluation (Pros + Cons, Possible failures, etc.)
%\input{060_WorkPlan.tex}% * Work Plan (Research Goals+- --> Paul Engelfield)
% Work Done (so far)
% Timetable

% MAke a Timeline of AR
% Check "Paul Engelfield" --> Good Report

% *5min sketch of the report at the begining

% Bibliography
\clearpage
\bibliographystyle{abbrvnat}
\bibliography{/home/kilgore/Dropbox/Public/Docs/mabp_bibliography.bib}
%\bibliography{Bibliography.bib}


\end{document}
